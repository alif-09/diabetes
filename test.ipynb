{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "df['age-label'] = pd.cut(df['age'], bins=[0, 9, 19, 59, 100], labels=['Child', 'Young_Adult', 'Adult', 'Elderly'])\n",
    "df.drop(['age'], axis=1, inplace=True)\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop(['diabetes'], axis=1)\n",
    "y = df['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate categorical and numerical columns\n",
    "cat_cols = X.select_dtypes(exclude=np.number).columns\n",
    "num_cols = X.select_dtypes(include=np.number).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Pipeline and Column Transformation\n",
    "category_pipeline = Pipeline(steps=[(\"one_hotencoding\", OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse=True))])\n",
    "numeric_pipeline = Pipeline(steps=[('scaling', StandardScaler())])\n",
    "full_processor = ColumnTransformer(transformers=[('numeric', numeric_pipeline, num_cols),\n",
    "                                                  ('categorical', category_pipeline, cat_cols)])\n",
    "X_preprocessed = full_processor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "[[18142   150]\n",
      " [  665  1043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     18292\n",
      "           1       0.87      0.61      0.72      1708\n",
      "\n",
      "    accuracy                           0.96     20000\n",
      "   macro avg       0.92      0.80      0.85     20000\n",
      "weighted avg       0.96      0.96      0.96     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lc_reg = LogisticRegression()\n",
    "lc_reg.fit(X_train, y_train)\n",
    "log_predict = lc_reg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(confusion_matrix(y_test, log_predict))\n",
    "print(classification_report(y_test, log_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "[[18174   118]\n",
      " [  513  1195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     18292\n",
      "           1       0.91      0.70      0.79      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.94      0.85      0.89     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rm_forest = RandomForestClassifier()\n",
    "rf_predict = rm_forest.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(confusion_matrix(y_test, rf_predict))\n",
    "print(classification_report(y_test, rf_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Imbalance with SMOTE\n",
    "sm = SMOTE(random_state=2)\n",
    "X_smote, y_smote = sm.fit_resample(X_preprocessed, y)\n",
    "\n",
    "# Split the balanced data into train and test sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Balanced Data):\n",
      "[[16219  2074]\n",
      " [ 2300 16007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88     18293\n",
      "           1       0.89      0.87      0.88     18307\n",
      "\n",
      "    accuracy                           0.88     36600\n",
      "   macro avg       0.88      0.88      0.88     36600\n",
      "weighted avg       0.88      0.88      0.88     36600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with balanced data\n",
    "lc_reg1 = LogisticRegression()\n",
    "log_predict1 = lc_reg1.fit(X1_train, y1_train).predict(X1_test)\n",
    "\n",
    "print(\"Logistic Regression (Balanced Data):\")\n",
    "print(confusion_matrix(y1_test, log_predict1))\n",
    "print(classification_report(y1_test, log_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Balanced Data):\n",
      "[[17766   527]\n",
      " [  518 17789]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     18293\n",
      "           1       0.97      0.97      0.97     18307\n",
      "\n",
      "    accuracy                           0.97     36600\n",
      "   macro avg       0.97      0.97      0.97     36600\n",
      "weighted avg       0.97      0.97      0.97     36600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with balanced data\n",
    "rm_forest1 = RandomForestClassifier()\n",
    "rf_predict1 = rm_forest1.fit(X1_train, y1_train).predict(X1_test)\n",
    "\n",
    "print(\"Random Forest (Balanced Data):\")\n",
    "print(confusion_matrix(y1_test, rf_predict1))\n",
    "print(classification_report(y1_test, rf_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score Random Forest (Imbalanced Data): 0.9541785969064936\n",
      "AUC Score for Logistic Regression (Balanced Data): 0.9597676700666362\n",
      "AUC Score for Random Forest (Balanced Data): 0.9957755241810763\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC for each model (continued)\n",
    "pred_prob2 = rm_forest.predict_proba(X_test)\n",
    "auc_score2 = roc_auc_score(y_test, pred_prob2[:, 1])\n",
    "print('AUC Score Random Forest (Imbalanced Data):', auc_score2)\n",
    "\n",
    "pred_prob3 = lc_reg1.predict_proba(X1_test)\n",
    "auc_score3 = roc_auc_score(y1_test, pred_prob3[:, 1])\n",
    "print('AUC Score for Logistic Regression (Balanced Data):', auc_score3)\n",
    "\n",
    "pred_prob4 = rm_forest1.predict_proba(X1_test)\n",
    "auc_score4 = roc_auc_score(y1_test, pred_prob4[:, 1])\n",
    "print('AUC Score for Random Forest (Balanced Data):', auc_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(lc_reg, 'logistic_regression_model.pkl')\n",
    "joblib.dump(rm_forest, 'random_forest_model.pkl')\n",
    "joblib.dump(lc_reg1, 'logistic_regression_balanced_model.pkl')\n",
    "joblib.dump(rm_forest1, 'random_forest_balanced_model.pkl')\n",
    "\n",
    "# Load the model\n",
    "loaded_lc_reg = joblib.load('logistic_regression_model.pkl')\n",
    "loaded_rm_forest = joblib.load('random_forest_model.pkl')\n",
    "loaded_lc_reg1 = joblib.load('logistic_regression_balanced_model.pkl')\n",
    "loaded_rm_forest1 = joblib.load('random_forest_balanced_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Predictions:\n",
      "[0 0 0 0 0 0 0]\n",
      "Random Forest Predictions:\n",
      "[0 0 0 0 0 0 1]\n",
      "Logistic Regression (Balanced Data) Predictions:\n",
      "[1 0 0 0 0 0 1]\n",
      "Random Forest (Balanced Data) Predictions:\n",
      "[0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the saved models\n",
    "loaded_lc_reg = joblib.load('logistic_regression_model.pkl')\n",
    "loaded_rm_forest = joblib.load('random_forest_model.pkl')\n",
    "loaded_lc_reg1 = joblib.load('logistic_regression_balanced_model.pkl')\n",
    "loaded_rm_forest1 = joblib.load('random_forest_balanced_model.pkl')\n",
    "\n",
    "# Create a new DataFrame for the new data\n",
    "new_data = pd.DataFrame({\n",
    "    'gender': ['Female', 'Female', 'Male', 'Female', 'Male', 'Female', 'Female'],\n",
    "    'age': [80.0, 54.0, 28.0, 36.0, 76.0, 20.0, 44.0],\n",
    "    'hypertension': [0, 0, 0, 0, 1, 0, 0],\n",
    "    'heart_disease': [1, 0, 0, 0, 1, 0, 0],\n",
    "    'smoking_history': ['never', 'No Info', 'never', 'current', 'current', 'never', 'never'],\n",
    "    'bmi': [25.19, 27.32, 27.32, 23.45, 20.14, 27.32, 19.31],\n",
    "    'HbA1c_level': [6.6, 6.6, 5.7, 5.0, 4.8, 6.6, 6.5],\n",
    "    'blood_glucose_level': [140, 80, 158, 155, 155, 85, 200]\n",
    "})\n",
    "\n",
    "# Preprocess the new data\n",
    "new_data['age-label'] = pd.cut(new_data['age'], bins=[0, 9, 19, 59, 100], labels=['Child', 'Young_Adult', 'Adult', 'Elderly'])\n",
    "new_data.drop(['age'], axis=1, inplace=True)\n",
    "\n",
    "# Apply the same transformations as before\n",
    "new_data_preprocessed = full_processor.transform(new_data)\n",
    "\n",
    "# Make predictions using the loaded models\n",
    "logistic_regression_predictions = loaded_lc_reg.predict(new_data_preprocessed)\n",
    "random_forest_predictions = loaded_rm_forest.predict(new_data_preprocessed)\n",
    "logistic_regression_balanced_predictions = loaded_lc_reg1.predict(new_data_preprocessed)\n",
    "random_forest_balanced_predictions = loaded_rm_forest1.predict(new_data_preprocessed)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Logistic Regression Predictions:\")\n",
    "print(logistic_regression_predictions)\n",
    "\n",
    "print(\"Random Forest Predictions:\")\n",
    "print(random_forest_predictions)\n",
    "\n",
    "print(\"Logistic Regression (Balanced Data) Predictions:\")\n",
    "print(logistic_regression_balanced_predictions)\n",
    "\n",
    "print(\"Random Forest (Balanced Data) Predictions:\")\n",
    "print(random_forest_balanced_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the preprocessor pipelines\n",
    "joblib.dump(full_processor, 'preprocessor_pipeline.pkl')\n",
    "\n",
    "# Load the preprocessor pipelines\n",
    "full_processor = joblib.load('preprocessor_pipeline.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Risk Percentages:\n",
      "31.82%\n",
      "0.52%\n",
      "1.92%\n",
      "0.22%\n",
      "2.43%\n",
      "1.07%\n",
      "16.76%\n",
      "Random Forest Risk Percentages:\n",
      "4.0%\n",
      "0.0%\n",
      "0.0%\n",
      "0.0%\n",
      "4.0%\n",
      "0.0%\n",
      "61.0%\n",
      "Logistic Regression (Balanced Data) Risk Percentages:\n",
      "83.35%\n",
      "5.74%\n",
      "17.97%\n",
      "2.24%\n",
      "25.59%\n",
      "10.56%\n",
      "62.11%\n",
      "Random Forest (Balanced Data) Risk Percentages:\n",
      "43.0%\n",
      "0.0%\n",
      "0.0%\n",
      "0.0%\n",
      "1.0%\n",
      "0.0%\n",
      "65.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the saved models\n",
    "loaded_lc_reg = joblib.load('logistic_regression_model.pkl')\n",
    "loaded_rm_forest = joblib.load('random_forest_model.pkl')\n",
    "loaded_lc_reg1 = joblib.load('logistic_regression_balanced_model.pkl')\n",
    "loaded_rm_forest1 = joblib.load('random_forest_balanced_model.pkl')\n",
    "\n",
    "# Create a new DataFrame for the new data\n",
    "new_data = pd.DataFrame({\n",
    "    'gender': ['Female', 'Female', 'Male', 'Female', 'Male', 'Female', 'Female'],\n",
    "    'age': [80.0, 54.0, 28.0, 36.0, 76.0, 20.0, 44.0],\n",
    "    'hypertension': [0, 0, 0, 0, 1, 0, 0],\n",
    "    'heart_disease': [1, 0, 0, 0, 1, 0, 0],\n",
    "    'smoking_history': ['never', 'No Info', 'never', 'current', 'current', 'never', 'never'],\n",
    "    'bmi': [25.19, 27.32, 27.32, 23.45, 20.14, 27.32, 19.31],\n",
    "    'HbA1c_level': [6.6, 6.6, 5.7, 5.0, 4.8, 6.6, 6.5],\n",
    "    'blood_glucose_level': [140, 80, 158, 155, 155, 85, 200]\n",
    "})\n",
    "\n",
    "# Preprocess the new data\n",
    "new_data['age-label'] = pd.cut(new_data['age'], bins=[0, 9, 19, 59, 100], labels=['Child', 'Young_Adult', 'Adult', 'Elderly'])\n",
    "new_data.drop(['age'], axis=1, inplace=True)\n",
    "\n",
    "# Apply the same transformations as before\n",
    "new_data_preprocessed = full_processor.transform(new_data)\n",
    "\n",
    "# Make predictions using the loaded models\n",
    "logistic_regression_probabilities = loaded_lc_reg.predict_proba(new_data_preprocessed)\n",
    "random_forest_probabilities = loaded_rm_forest.predict_proba(new_data_preprocessed)\n",
    "logistic_regression_balanced_probabilities = loaded_lc_reg1.predict_proba(new_data_preprocessed)\n",
    "random_forest_balanced_probabilities = loaded_rm_forest1.predict_proba(new_data_preprocessed)\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "logistic_regression_percentages = logistic_regression_probabilities[:, 1] * 100\n",
    "random_forest_percentages = random_forest_probabilities[:, 1] * 100\n",
    "logistic_regression_balanced_percentages = logistic_regression_balanced_probabilities[:, 1] * 100\n",
    "random_forest_balanced_percentages = random_forest_balanced_probabilities[:, 1] * 100\n",
    "\n",
    "# Round the percentages to two decimal places\n",
    "logistic_regression_percentages = np.round(logistic_regression_percentages, 2)\n",
    "random_forest_percentages = np.round(random_forest_percentages, 2)\n",
    "logistic_regression_balanced_percentages = np.round(logistic_regression_balanced_percentages, 2)\n",
    "random_forest_balanced_percentages = np.round(random_forest_balanced_percentages, 2)\n",
    "\n",
    "# Print the risk percentages\n",
    "print(\"Logistic Regression Risk Percentages:\")\n",
    "for percentage in logistic_regression_percentages:\n",
    "    print(f\"{percentage}%\")\n",
    "\n",
    "print(\"Random Forest Risk Percentages:\")\n",
    "for percentage in random_forest_percentages:\n",
    "    print(f\"{percentage}%\")\n",
    "\n",
    "print(\"Logistic Regression (Balanced Data) Risk Percentages:\")\n",
    "for percentage in logistic_regression_balanced_percentages:\n",
    "    print(f\"{percentage}%\")\n",
    "\n",
    "print(\"Random Forest (Balanced Data) Risk Percentages:\")\n",
    "for percentage in random_forest_balanced_percentages:\n",
    "    print(f\"{percentage}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
